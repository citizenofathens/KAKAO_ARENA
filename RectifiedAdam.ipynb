{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.Tensor()\n",
    "\n",
    "\n",
    "beta1 = tf.Variable(1. , tf.dtypes.float16 ,shape=tf.TensorShape(None))\n",
    "beta2 =\n",
    "step =\n",
    "\n",
    "(1 - )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4275515357.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  File \u001B[1;32m\"C:\\Users\\DATA\\AppData\\Local\\Temp\\ipykernel_40184\\4275515357.py\"\u001B[1;36m, line \u001B[1;32m1\u001B[0m\n\u001B[1;33m    class RectifiedAdam(tf.)\u001B[0m\n\u001B[1;37m                           ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class RectifiedAdam(tf.)\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "    # m_zero, v_zero moving 1st, 2nd moment\n",
    "    # p_inf <- 2/(1-beta2)-1  Simple Moving-Average 의 최대 길이를 계산\n",
    "    from typing import List\n",
    "\n",
    "    def _single_tensor_radam(self , params:List[tf.Tensor]\n",
    "                                   , grads:List[tf.Tensor]\n",
    "                                   , exp_avgs:List[tf.Tensor]\n",
    "                                    , exp_avg_sqs:List[tf.Tensor]\n",
    "                                    ,state_steps:List[tf.Tensor]\n",
    "                                    ,*\n",
    "                             , beta1 :tf.float16\n",
    "                             , beta2  :tf.float16\n",
    "                             ,lr : tf.float16\n",
    "                             ,weight_decay: tf.float\n",
    "                             ,eps:float ):\n",
    "\n",
    "        for i, param in enumerate(params):\n",
    "            grads = grads[i]\n",
    "            exp_avg = exp_avgs[i]\n",
    "            exp_avg_sq = exp_avg_sqs[i]\n",
    "            step_t = state_steps[i]\n",
    "\n",
    "            # update step\n",
    "            step_t +=1\n",
    "            # tensor item\n",
    "            step = step_t.items()\n",
    "\n",
    "            # beta2  (1-beta2)*(grads**2)\n",
    "            # gradient = func*(param*step)\n",
    "            # v_zero  = beta2*(v_zero*step) + (1-beta2)*(grad*step **2) 이전 시점 v_zero\n",
    "\n",
    "            # 최초  exp_avg (지수이동평균값을 parameter로 받으므로 받은 후 exp_avg t시점은 t+1 시점을 만든다)\n",
    "\n",
    "            bias_correction1 = 1-beta1**step\n",
    "            bias_correction2=  1- beta2 **step\n",
    "\n",
    "            if weight_decay != 0:\n",
    "                # torch : grad = grad.add(param, alpha=weight_decay)\n",
    "                grad =  grad+ (weight_decay*param)\n",
    "\n",
    "\n",
    "            exp_avg = tf.math.multiply(exp_avg,beta1) + ( 1- beta1)*grads\n",
    "            exp_avg_sq = tf.math.multiply( exp_avg_sq*beta2) + (1-beta2) * tf.math.multiply(grads*grads)\n",
    "            # Decay the first and second moment running average coefficient\n",
    "            #bias_correction = bias_correction / (1-beta1**eps)\n",
    "\n",
    "            # decay rate에 step을 제곱하여 1에서 뺀값으로 나누어\n",
    "            # 지수이동평균을 나누어 편향을 수정한다\n",
    "            bias_corrected_exp_avgs = exp_avgs/bias_correction1\n",
    "            # 지수이동평균 추정치 길이의 최대값\n",
    "            p_inf = 2/(1-beta2)-1\n",
    "\n",
    "            # compute the length of the approximated SMA 지수이동평균 길이의 추정치를 계산\n",
    "            p_t =  p_inf-2*step*(beta2**step) / bias_correction2\n",
    "\n",
    "            #\n",
    "#            bias_correction =\n",
    "\n",
    "            # 음수 값이 되지 않는선\n",
    "            if p_t > 5:\n",
    "                # Compute adaptive learning rate\n",
    "                lr = tf.math.sqrt(bias_correction2)/tf.math.sqrt(exp_avg_sqs+eps )\n",
    "                # Comput the variance reccitfication term\n",
    "                rectification_term = tf.math.sqrt((p_t -4)(p_t-2) *p_inf / ((p_inf-4)(p_inf-2)*p_t))\n",
    "\n",
    "                # add_(input, other, alpha) -> input+ (other*alpha)\n",
    "                # param.add_(bias_corrected_exp_avg * lr , alpha=-1.0)\n",
    "                # === param - bias_corrected_exp_avg *lr\n",
    "                alpha=-1\n",
    "                param=  param -( rectification_term * bias_corrected_exp_avgs*lr*alpha)\n",
    "                # 이것 자체로 param 은 t시점이된다\n",
    "            else:\n",
    "                param=  param -( bias_corrected_exp_avgs*lr*alpha)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}