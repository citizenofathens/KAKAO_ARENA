{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv(\"../dataset/train.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 2, 1], dtype=int8)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['discourse_effectiveness'].astype('category').cat.codes.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.cudaDB_PATH = f'../input/processed'\n",
    "VOCAB_DIR = \\\n",
    "    os.path.join(DB_PATH, 'vocab')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "vocab =  [line.split('\\t')[0] for line in open(os.path.join(VOCAB_DIR,'spm.vocab'), encoding='utf-8').readlines()]\n",
    "token2id = dict([(w,i) for i,w in enumerate(vocab)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "{'<unk>': 0,\n '<s>': 1,\n '</s>': 2,\n '▁t': 3,\n '▁th': 4,\n '▁a': 5,\n '▁the': 6,\n '▁s': 7,\n 'in': 8,\n '▁w': 9,\n 're': 10,\n '▁o': 11,\n '▁c': 12,\n '▁i': 13,\n 'en': 14,\n 'er': 15,\n '▁b': 16,\n 'ou': 17,\n 'le': 18,\n 'at': 19,\n '▁p': 20,\n '▁to': 21,\n 'on': 22,\n 'ing': 23,\n '▁h': 24,\n 'or': 25,\n '▁f': 26,\n '▁m': 27,\n 'an': 28,\n '▁d': 29,\n '▁an': 30,\n 'es': 31,\n '▁e': 32,\n '▁be': 33,\n '▁and': 34,\n 'ar': 35,\n 'ent': 36,\n '▁in': 37,\n 'ot': 38,\n '▁of': 39,\n 'll': 40,\n 'om': 41,\n '▁n': 42,\n 'us': 43,\n 'it': 44,\n 'ct': 45,\n '▁st': 46,\n 'ed': 47,\n 'as': 48,\n '▁g': 49,\n '▁that': 50,\n 've': 51,\n 'ld': 52,\n '▁is': 53,\n '▁y': 54,\n '▁wh': 55,\n '▁it': 56,\n 'is': 57,\n 'ch': 58,\n 'al': 59,\n '▁l': 60,\n 'ion': 61,\n '▁you': 62,\n 'ould': 63,\n '▁v': 64,\n '▁on': 65,\n 'dent': 66,\n 'ic': 67,\n 'ol': 68,\n '▁ha': 69,\n 'ut': 70,\n '▁for': 71,\n 'ay': 72,\n '▁they': 73,\n 'et': 74,\n '▁re': 75,\n 'ow': 76,\n '▁stu': 77,\n 'ke': 78,\n 'op': 79,\n '▁student': 80,\n 'id': 81,\n 'ir': 82,\n '▁are': 83,\n '▁have': 84,\n 'ce': 85,\n 'ro': 86,\n 'lect': 87,\n '▁can': 88,\n 'ver': 89,\n '▁elect': 90,\n 'st': 91,\n '▁not': 92,\n 'el': 93,\n '▁we': 94,\n 'un': 95,\n 'ome': 96,\n 'ge': 97,\n 'ig': 98,\n 'use': 99,\n 'ur': 100,\n '▁do': 101,\n '▁students': 102,\n 'res': 103,\n '▁vot': 104,\n '▁mo': 105,\n 'ers': 106,\n '▁sh': 107,\n 'th': 108,\n '▁li': 109,\n '▁as': 110,\n '▁would': 111,\n '▁pe': 112,\n '▁or': 113,\n 'ad': 114,\n 'ly': 115,\n '▁this': 116,\n '▁te': 117,\n '▁al': 118,\n '▁peop': 119,\n 'ill': 120,\n '▁people': 121,\n 'ith': 122,\n 'im': 123,\n '▁bec': 124,\n '▁if': 125,\n '▁with': 126,\n '▁elector': 127,\n '▁pro': 128,\n '▁le': 129,\n 'ri': 130,\n 'ause': 131,\n '▁go': 132,\n 'se': 133,\n '▁their': 134,\n '▁sch': 135,\n 'ool': 136,\n 'am': 137,\n 'ul': 138,\n '▁ne': 139,\n '▁school': 140,\n '▁because': 141,\n '▁ex': 142,\n '▁ch': 143,\n '▁ab': 144,\n '▁com': 145,\n 'all': 146,\n '▁all': 147,\n '▁but': 148,\n '▁ma': 149,\n '▁at': 150,\n 'ate': 151,\n '▁will': 152,\n '▁k': 153,\n '▁cl': 154,\n '▁fa': 155,\n '▁more': 156,\n '▁so': 157,\n 'ant': 158,\n '▁con': 159,\n '▁wor': 160,\n '▁some': 161,\n '▁su': 162,\n '▁j': 163,\n '▁there': 164,\n 'ect': 165,\n 'ation': 166,\n '▁electoral': 167,\n 'ity': 168,\n 'ter': 169,\n '▁car': 170,\n '▁should': 171,\n '▁get': 172,\n '▁pres': 173,\n 'ra': 174,\n 'ust': 175,\n '▁de': 176,\n '▁them': 177,\n 'ere': 178,\n 'nt': 179,\n '▁like': 180,\n '▁col': 181,\n 'ach': 182,\n '▁se': 183,\n 'one': 184,\n 'igh': 185,\n '▁what': 186,\n 'out': 187,\n '▁colle': 188,\n 'elp': 189,\n 'ident': 190,\n '▁help': 191,\n 'ass': 192,\n 'rom': 193,\n '▁by': 194,\n '▁was': 195,\n 'od': 196,\n '▁pl': 197,\n '▁college': 198,\n '▁vote': 199,\n 'king': 200,\n '▁when': 201,\n 'pp': 202,\n 'iv': 203,\n 'ort': 204,\n '▁your': 205,\n 'end': 206,\n '▁could': 207,\n '▁un': 208,\n 'ally': 209,\n '▁tim': 210,\n 'ions': 211,\n '▁r': 212,\n '▁from': 213,\n 'ble': 214,\n '▁one': 215,\n '▁thin': 216,\n 'ice': 217,\n '▁president': 218,\n 'ss': 219,\n '▁who': 220,\n 'ff': 221,\n '▁oth': 222,\n '▁ta': 223,\n '▁just': 224,\n '▁think': 225,\n '▁dri': 226,\n 'ight': 227,\n 'est': 228,\n '▁class': 229,\n '▁kn': 230,\n 'gh': 231,\n '▁how': 232,\n 'so': 233,\n '▁out': 234,\n 'ates': 235,\n '▁about': 236,\n '▁know': 237,\n 'ci': 238,\n '▁also': 239,\n 'ist': 240,\n '▁time': 241,\n '▁teach': 242,\n '▁u': 243,\n '▁man': 244,\n '▁ev': 245,\n 'ject': 246,\n 'ple': 247,\n 'ive': 248,\n 'and': 249,\n 'arn': 250,\n '▁ven': 251,\n '▁us': 252,\n 'ment': 253,\n '▁want': 254,\n 'ough': 255,\n '▁learn': 256,\n '▁make': 257,\n '▁venus': 258,\n '▁ever': 259,\n '▁he': 260,\n '▁whi': 261,\n '▁has': 262,\n 'em': 263,\n '▁up': 264,\n '▁way': 265,\n '▁project': 266,\n 'ving': 267,\n '▁sp': 268,\n '▁tr': 269,\n '▁ad': 270,\n '▁thing': 271,\n 'art': 272,\n '▁act': 273,\n 'ign': 274,\n '▁exp': 275,\n 'oo': 276,\n 'um': 277,\n '▁many': 278,\n '▁don': 279,\n 'eth': 280,\n '▁our': 281,\n '▁fe': 282,\n '▁other': 283,\n '▁need': 284,\n '▁even': 285,\n 'ces': 286,\n '▁di': 287,\n 'qu': 288,\n '▁work': 289,\n '▁may': 290,\n '▁every': 291,\n '▁ar': 292,\n 'ain': 293,\n 'il': 294,\n '▁me': 295,\n 'ure': 296,\n '▁im': 297,\n 'ine': 298,\n 'are': 299,\n 'ular': 300,\n 'ide': 301,\n '▁no': 302,\n '▁en': 303,\n '▁som': 304,\n '▁po': 305,\n '▁bet': 306,\n 'og': 307,\n 'mer': 308,\n '▁ph': 309,\n '▁my': 310,\n '▁states': 311,\n '▁say': 312,\n '▁pers': 313,\n '▁then': 314,\n 'ie': 315,\n 'ck': 316,\n '▁good': 317,\n 'oun': 318,\n 'ies': 319,\n 'vice': 320,\n '▁cars': 321,\n '▁comm': 322,\n 'ens': 323,\n '▁op': 324,\n '▁home': 325,\n '▁than': 326,\n '▁any': 327,\n 'ag': 328,\n '▁comp': 329,\n '▁most': 330,\n '▁person': 331,\n '▁des': 332,\n '▁see': 333,\n 'de': 334,\n '▁int': 335,\n 'her': 336,\n '▁chan': 337,\n 'reat': 338,\n 'ars': 339,\n '▁why': 340,\n '▁face': 341,\n 'ard': 342,\n 'fe': 343,\n '▁sa': 344,\n 'ound': 345,\n '▁take': 346,\n '▁votes': 347,\n 'ans': 348,\n '▁only': 349,\n '▁better': 350,\n 'ason': 351,\n 'unity': 352,\n 'ting': 353,\n 'ind': 354,\n '▁electors': 355,\n 'age': 356,\n 'for': 357,\n '▁reason': 358,\n '▁diff': 359,\n '▁gr': 360,\n 'ress': 361,\n 'ong': 362,\n 'ame': 363,\n '▁its': 364,\n '▁pop': 365,\n 'ue': 366,\n 'ery': 367,\n '▁over': 368,\n '▁sy': 369,\n '▁these': 370,\n 'our': 371,\n '▁able': 372,\n '▁dec': 373,\n 'os': 374,\n 'ose': 375,\n '▁driver': 376,\n 'stem': 377,\n '▁system': 378,\n '▁use': 379,\n 'way': 380,\n 'ult': 381,\n 'ep': 382,\n 'ace': 383,\n '▁which': 384,\n 'ast': 385,\n '▁plan': 386,\n '▁ac': 387,\n 'ount': 388,\n 'ore': 389,\n '▁things': 390,\n '▁new': 391,\n 'der': 392,\n '▁em': 393,\n '▁very': 394,\n '▁someth': 395,\n '▁being': 396,\n '▁feel': 397,\n '▁something': 398,\n '▁part': 399,\n '▁imp': 400,\n '▁happ': 401,\n '▁learning': 402,\n 'ous': 403,\n '▁sum': 404,\n '▁2': 405,\n '▁ide': 406,\n 'form': 407,\n '▁were': 408,\n '▁summer': 409,\n 'ree': 410,\n 'line': 411,\n '▁state': 412,\n '▁community': 413,\n 'iz': 414,\n '▁life': 415,\n '▁tech': 416,\n '▁had': 417,\n '▁per': 418,\n 'du': 419,\n '▁teacher': 420,\n '▁ye': 421,\n '▁popular': 422,\n '▁online': 423,\n '▁going': 424,\n '▁differe': 425,\n 'olog': 426,\n '▁planet': 427,\n '▁hum': 428,\n 'wn': 429,\n 'less': 430,\n 'ook': 431,\n '▁day': 432,\n '▁techn': 433,\n 'ade': 434,\n 'ial': 435,\n '▁ke': 436,\n '▁1': 437,\n '▁off': 438,\n '▁projects': 439,\n '▁activ': 440,\n '▁mu': 441,\n '▁classes': 442,\n '▁dis': 443,\n '▁teachers': 444,\n '▁might': 445,\n '▁att': 446,\n '▁ear': 447,\n '▁ser': 448,\n '▁cand': 449,\n '▁really': 450,\n 'ology': 451,\n '▁design': 452,\n 'riend': 453,\n '▁much': 454,\n 'able': 455,\n '▁election': 456,\n '▁own': 457,\n 'ves': 458,\n '▁different': 459,\n '▁friend': 460,\n '▁candid': 461,\n '▁ben': 462,\n '▁while': 463,\n '▁win': 464,\n '▁bel': 465,\n '▁opin': 466,\n '▁emot': 467,\n 'ities': 468,\n '▁does': 469,\n 'ef': 470,\n 'other': 471,\n '▁been': 472,\n '▁sm': 473,\n 'cess': 474,\n 'ence': 475,\n '▁keep': 476,\n 'led': 477,\n '▁allow': 478,\n '▁exam': 479,\n '▁ag': 480,\n 'ated': 481,\n '▁kid': 482,\n 'ance': 483,\n 'ry': 484,\n '▁technology': 485,\n '▁earth': 486,\n '▁ro': 487,\n '▁did': 488,\n '▁res': 489,\n '▁pre': 490,\n '▁ass': 491,\n 'ip': 492,\n '▁dist': 493,\n '▁doing': 494,\n '▁benef': 495,\n 'ang': 496,\n '▁idea': 497,\n 'oc': 498,\n '▁example': 499,\n '▁show': 500,\n 'kes': 501,\n '▁having': 502,\n 'ack': 503,\n '▁aut': 504,\n '▁am': 505,\n 'ess': 506,\n '▁now': 507,\n '▁af': 508,\n 'cial': 509,\n '▁ext': 510,\n 'ying': 511,\n 'ick': 512,\n 'ful': 513,\n '▁less': 514,\n '▁mars': 515,\n '▁belie': 516,\n '▁best': 517,\n '▁comput': 518,\n '▁stud': 519,\n '▁well': 520,\n '▁count': 521,\n '▁another': 522,\n '▁lot': 523,\n '▁someone': 524,\n '▁driving': 525,\n 'ones': 526,\n 'ph': 527,\n 'ire': 528,\n '▁giv': 529,\n 'ub': 530,\n 'ert': 531,\n '▁land': 532,\n '▁under': 533,\n '▁kids': 534,\n '▁after': 535,\n '▁into': 536,\n '▁though': 537,\n '▁service': 538,\n '▁thr': 539,\n '▁qu': 540,\n 'blem': 541,\n '▁look': 542,\n 'if': 543,\n '▁problem': 544,\n '▁great': 545,\n '▁still': 546,\n '▁voting': 547,\n '▁where': 548,\n '▁advice': 549,\n 'int': 550,\n '▁jo': 551,\n '▁right': 552,\n 'les': 553,\n '▁acc': 554,\n '▁cont': 555,\n '▁ask': 556,\n '▁ali': 557,\n 'pport': 558,\n '▁world': 559,\n 'ab': 560,\n 'act': 561,\n '▁voters': 562,\n 'sel': 563,\n 'vel': 564,\n 'ways': 565,\n '▁par': 566,\n 'cent': 567,\n '▁driverless': 568,\n '▁his': 569,\n 'duc': 570,\n '▁sur': 571,\n '▁too': 572,\n '▁same': 573,\n '▁rep': 574,\n '▁phones': 575,\n 'ually': 576,\n 'ely': 577,\n '▁she': 578,\n 'thing': 579,\n '▁tell': 580,\n '▁made': 581,\n '▁auth': 582,\n '▁sport': 583,\n '▁each': 584,\n '▁believe': 585,\n 'ish': 586,\n '▁eas': 587,\n '▁tal': 588,\n '▁change': 589,\n '▁others': 590,\n '▁author': 591,\n '▁designed': 592,\n 'uring': 593,\n '▁inst': 594,\n '▁let': 595,\n '00': 596,\n '▁art': 597,\n 'ible': 598,\n '▁choo': 599,\n 'cl': 600,\n 'xt': 601,\n '▁wr': 602,\n '▁those': 603,\n 'ited': 604,\n '▁making': 605,\n '▁through': 606,\n 'ell': 607,\n '▁fir': 608,\n '▁give': 609,\n '▁everyone': 610,\n 'ric': 611,\n '▁cho': 612,\n '▁first': 613,\n 'pt': 614,\n '▁around': 615,\n '▁expl': 616,\n '▁assign': 617,\n '▁br': 618,\n '▁cons': 619,\n '▁3': 620,\n '▁read': 621,\n 'ict': 622,\n '▁bas': 623,\n 'icle': 624,\n '▁always': 625,\n '▁import': 626,\n '▁year': 627,\n '▁won': 628,\n 'ical': 629,\n '▁friends': 630,\n '▁during': 631,\n '▁extra': 632,\n '▁candidate': 633,\n 'ild': 634,\n '▁co': 635,\n '▁dont': 636,\n 'oy': 637,\n '▁hard': 638,\n '▁such': 639,\n 'te': 640,\n 'ning': 641,\n '▁human': 642,\n '▁dang': 643,\n '▁put': 644,\n 'stand': 645,\n '▁tw': 646,\n '▁phone': 647,\n '▁requ': 648,\n 'day': 649,\n '▁benefit': 650,\n '▁important': 651,\n '▁bad': 652,\n '▁fact': 653,\n '▁computer': 654,\n '▁her': 655,\n '▁sim': 656,\n '▁mat': 657,\n '▁comple': 658,\n 'ily': 659,\n '▁big': 660,\n '▁creat': 661,\n '▁cell': 662,\n '▁find': 663,\n '▁schools': 664,\n 'fore': 665,\n '▁high': 666,\n '▁pol': 667,\n 'own': 668,\n '▁educ': 669,\n '▁pr': 670,\n 'ak': 671,\n 'ments': 672,\n '▁activities': 673,\n '▁understand': 674,\n 'ase': 675,\n '▁emotions': 676,\n 'cur': 677,\n 'ever': 678,\n '▁exper': 679,\n '▁long': 680,\n '▁said': 681,\n 'ite': 682,\n '▁ca': 683,\n '▁play': 684,\n '▁fun': 685,\n '▁decis': 686,\n '▁getting': 687,\n 'ber': 688,\n '▁eff': 689,\n '▁back': 690,\n 'ru': 691,\n '▁tra': 692,\n '▁app': 693,\n 'ations': 694,\n '▁percent': 695,\n 'ner': 696,\n 'ract': 697,\n 'ors': 698,\n '▁gen': 699,\n '▁poss': 700,\n '▁happen': 701,\n 'ft': 702,\n '▁5': 703,\n '▁conf': 704,\n 'raph': 705,\n '▁nas': 706,\n '▁nasa': 707,\n '▁point': 708,\n 'ond': 709,\n 'jor': 710,\n '▁attend': 711,\n '▁form': 712,\n '▁real': 713,\n '▁sit': 714,\n 'ures': 715,\n 'etim': 716,\n '▁partic': 717,\n '▁unf': 718,\n '▁major': 719,\n '▁without': 720,\n '▁bu': 721,\n '▁sci': 722,\n 'ved': 723,\n 'ib': 724,\n '▁gener': 725,\n '▁inform': 726,\n '▁mult': 727,\n '▁experi': 728,\n '▁reasons': 729,\n 'dit': 730,\n '▁opinion': 731,\n 'ution': 732,\n 'be': 733,\n '▁sports': 734,\n '▁end': 735,\n '▁come': 736,\n '▁el': 737,\n '▁choice': 738,\n '▁education': 739,\n '▁choose': 740,\n 'ren': 741,\n 'ier': 742,\n '▁fut': 743,\n 'ertain': 744,\n '▁actually': 745,\n '▁process': 746,\n 'room': 747,\n 'air': 748,\n 'ced': 749,\n '▁run': 750,\n 'ention': 751,\n '▁adv': 752,\n 'lic': 753,\n '▁cle': 754,\n '▁sometim': 755,\n 'ead': 756,\n '▁start': 757,\n '▁require': 758,\n '▁using': 759,\n 'ious': 760,\n '▁fam': 761,\n '▁aliens': 762,\n 'ost': 763,\n 'iple': 764,\n 'ricular': 765,\n '▁pass': 766,\n '▁express': 767,\n 'ise': 768,\n '▁multiple': 769,\n '▁pict': 770,\n '▁talk': 771,\n '▁article': 772,\n '▁classroom': 773,\n '▁place': 774,\n '▁la': 775,\n 'arent': 776,\n '▁amer': 777,\n '▁however': 778,\n '▁arg': 779,\n '▁sk': 780,\n '▁americ': 781,\n '▁ve': 782,\n 'ince': 783,\n '▁parag': 784,\n '▁lead': 785,\n '▁opinions': 786,\n '▁cause': 787,\n 'ating': 788,\n '▁future': 789,\n '▁landform': 790,\n '▁humans': 791,\n '▁stress': 792,\n '▁cal': 793,\n '▁sl': 794,\n '▁reg': 795,\n '▁cre': 796,\n '▁united': 797,\n '▁away': 798,\n '▁fin': 799,\n '▁hand': 800,\n '▁parent': 801,\n 'pe': 802,\n 'ists': 803,\n '▁particip': 804,\n 'iss': 805,\n '▁down': 806,\n '▁years': 807,\n '▁says': 808,\n '▁sometimes': 809,\n '▁activity': 810,\n 'als': 811,\n '▁sol': 812,\n 'ety': 813,\n '▁rel': 814,\n 'ather': 815,\n '▁unfair': 816,\n '▁facial': 817,\n 'urn': 818,\n '▁information': 819,\n '▁two': 820,\n '▁extracur': 821,\n '▁spe': 822,\n 'erest': 823,\n '▁paragraph': 824,\n 'ize': 825,\n '▁top': 826,\n '▁study': 827,\n 'ility': 828,\n '▁extracurricular': 829,\n '▁bre': 830,\n '▁decision': 831,\n 'itt': 832,\n '▁env': 833,\n '▁times': 834,\n '▁country': 835,\n 'ram': 836,\n 'ons': 837,\n 'oth': 838,\n '▁mon': 839,\n '▁cam': 840,\n '▁again': 841,\n '▁job': 842,\n '▁try': 843,\n '▁never': 844,\n 'ary': 845,\n 'selves': 846,\n '▁opt': 847,\n '▁since': 848,\n 'ional': 849,\n '▁maybe': 850,\n '▁ob': 851,\n '▁grad': 852,\n '▁child': 853,\n '▁interest': 854,\n 'ody': 855,\n '▁cit': 856,\n '▁stay': 857,\n '▁chance': 858,\n '▁taking': 859,\n '▁drive': 860,\n '▁fo': 861,\n '▁sec': 862,\n '▁pick': 863,\n '▁got': 864,\n 'ia': 865,\n '▁wrong': 866,\n '▁scient': 867,\n '▁resp': 868,\n '▁used': 869,\n '▁enough': 870,\n 'ether': 871,\n '▁care': 872,\n 'ding': 873,\n '▁break': 874,\n 'read': 875,\n '▁citiz': 876,\n '▁happy': 877,\n '▁trying': 878,\n '▁found': 879,\n '▁before': 880,\n '▁cr': 881,\n '▁support': 882,\n '▁instead': 883,\n '▁foc': 884,\n '▁sour': 885,\n '▁nat': 886,\n 'ory': 887,\n '▁num': 888,\n 'ile': 889,\n 'ove': 890,\n 'per': 891,\n 'elf': 892,\n '▁makes': 893,\n '▁thought': 894,\n '▁free': 895,\n '▁feeling': 896,\n '▁prov': 897,\n '▁ways': 898,\n '▁likely': 899,\n '▁certain': 900,\n '▁distance': 901,\n '▁focus': 902,\n '▁dem': 903,\n '▁mean': 904,\n '▁become': 905,\n '▁done': 906,\n '▁prog': 907,\n 'ix': 908,\n '▁anything': 909,\n '▁winner': 910,\n 'ural': 911,\n '▁themselves': 912,\n '▁space': 913,\n '▁name': 914,\n '▁envir': 915,\n '▁situ': 916,\n '▁due': 917,\n 'usion': 918,\n '▁aver': 919,\n '▁bus': 920,\n '▁turn': 921,\n '▁sub': 922,\n '▁repres': 923,\n '▁last': 924,\n '▁rec': 925,\n '▁vide': 926,\n '▁parents': 927,\n '▁danger': 928,\n '▁fair': 929,\n '▁sure': 930,\n '▁val': 931,\n '▁concl': 932,\n '▁topic': 933,\n '▁second': 934,\n 'ull': 935,\n 'ger': 936,\n '▁meth': 937,\n '▁experience': 938,\n 'ublic': 939,\n '▁road': 940,\n '▁method': 941,\n '▁attention': 942,\n '▁few': 943,\n '▁prob': 944,\n '▁chang': 945,\n '▁majority': 946,\n 'erm': 947,\n 'wor': 948,\n '▁average': 949,\n 'ically': 950,\n '▁represent': 951,\n 'ouse': 952,\n 'ared': 953,\n '▁citizens': 954,\n 'ied': 955,\n '▁pay': 956,\n 'ably': 957,\n 'ours': 958,\n '▁19': 959,\n 'ac': 960,\n 'icy': 961,\n 'rect': 962,\n '▁next': 963,\n '▁working': 964,\n 'iting': 965,\n '▁chall': 966,\n 'ys': 967,\n '▁distract': 968,\n '▁candidates': 969,\n '▁source': 970,\n '▁lar': 971,\n '▁him': 972,\n '▁sen': 973,\n 'red': 974,\n 'ward': 975,\n '▁inv': 976,\n '▁participate': 977,\n '▁200': 978,\n '▁opport': 979,\n '▁lim': 980,\n 'ks': 981,\n 'ives': 982,\n '▁grade': 983,\n '▁skill': 984,\n '▁challen': 985,\n '▁det': 986,\n '▁environ': 987,\n 'sure': 988,\n '▁program': 989,\n '▁bring': 990,\n 'icial': 991,\n '▁dr': 992,\n '▁litt': 993,\n 'ual': 994,\n '▁test': 995,\n '▁problems': 996,\n '▁both': 997,\n 'ower': 998,\n '▁little': 999,\n ...}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "token2id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import cate_dataset\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    learning_rate = 3.0e-4 # 러닝 레이트\n",
    "    batch_size=1024 # 배치 사이즈\n",
    "    num_workers=4 # 워커의 개수\n",
    "    print_freq=100 # 결과 출력 빈도\n",
    "    start_epoch=0 # 시작 에폭\n",
    "    num_train_epochs=10 # 학습할 에폭수\n",
    "    warmup_steps=100 # lr을 서서히 증가시킬 step 수\n",
    "    max_grad_norm=10 # 그래디언트\n",
    "    weight_decay=0.01\n",
    "    dropout=0.2 # dropout 확률\n",
    "    hidden_size=512 # 은닉 크기\n",
    "    intermediate_size = 256 # TRANSFORMER 셀의 intermediate 크기\n",
    "    nlayers=2 # BERT 의 층수\n",
    "    nheads=8 # BERT 의 head 개수\n",
    "    seq_len=64 # 토큰의 최대 길이\n",
    "    #n_b_cls = 57 + 1  # 대카테고리 개수\n",
    "    n_b_cls = 3  # 대카테고리 개수\n",
    "    # n_m_cls = 552 + 1  # 중카테고리 개수\n",
    "    # n_s_cls = 3190 + 1  # 소카테고리 개수\n",
    "    # n_d_cls = 404 + 1  # 세카테고리 개수\n",
    "    vocab_size = 32000 # 토큰의 유니크 인덱스 개수\n",
    "#    img_feat_size = 2048 #  이미지 피처 벡터의 크기\n",
    "    type_vocab_size = 30 # 타입의 유니크 인덱스 개수\n",
    "    csv_path = os.path.join(DB_PATH, 'train.csv')\n",
    "#    h5_path = os.path.join(DB_PATH, 'train_img_feat.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading...\n"
     ]
    }
   ],
   "source": [
    "print('loading...')\n",
    "train_df = pd.read_csv(CFG.csv_path , dtype={'tokens' : str})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import cate_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_db = cate_dataset.CateDataset(train_df, token2id,\n",
    "                                CFG.seq_len , CFG.type_vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        train_db, batch_size=CFG.batch_size , shuffle=True , drop_last=True,\n",
    "        num_workers=CFG.num_workers,pin_memory=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.utils.data.dataloader.DataLoader at 0x1fa475d43a0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import cate_model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 카테고리 분류기 모델을 생성함\n",
    "model = cate_model.CateClassifier(CFG)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "CateClassifier(\n  (text_encoder): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 512, padding_idx=0)\n      (position_embeddings): Embedding(64, 512)\n      (token_type_embeddings): Embedding(30, 512)\n      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=256, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=256, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.2, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=256, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=256, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.2, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=512, out_features=512, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (b_cls): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=3, bias=True)\n  )\n)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "CateClassifier(\n  (text_encoder): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(32000, 512, padding_idx=0)\n      (position_embeddings): Embedding(64, 512)\n      (token_type_embeddings): Embedding(30, 512)\n      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.2, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=256, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=256, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.2, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.2, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=256, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=256, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.2, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=512, out_features=512, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (b_cls): Sequential(\n    (0): Linear(in_features=1024, out_features=512, bias=True)\n    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    (2): Dropout(p=0.2, inplace=False)\n    (3): ReLU()\n    (4): Linear(in_features=512, out_features=3, bias=True)\n  )\n)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "def count_parameter(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters:  19854339\n"
     ]
    }
   ],
   "source": [
    "print('parameters: ', count_parameter(model))\n",
    "# 파라미터를 가중치라고도 한다"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import torch\n",
    "# GPU가 2개 이상이면 데이터 페럴렐로 학습 가능하게 만듦\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gpu"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "const = tf.constant([1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24732\\2607220616.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mconst\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    511\u001B[0m         \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy_ops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnp_config\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    512\u001B[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001B[1;32m--> 513\u001B[1;33m     \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    514\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    515\u001B[0m   \u001B[1;33m@\u001B[0m\u001B[0mstaticmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = [1]\n",
    "const.split(1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24732\\3533014117.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "arr.split(1,1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'const' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22796\\2501392508.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconst\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'const' is not defined"
     ]
    }
   ],
   "source": [
    "type(const)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22796\\333894259.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnn\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnn\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m t = np.array([[[0, 1, 2],\n\u001B[0;32m      4\u001B[0m                [3, 4, 5]],\n\u001B[0;32m      5\u001B[0m               [[6, 7, 8],\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "!pip install torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_22796\\1920727496.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}